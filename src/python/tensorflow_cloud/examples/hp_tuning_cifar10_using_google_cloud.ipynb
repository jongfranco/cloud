{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztj7SjzXyu0p"
      },
      "source": [
        "# HP Tuning CIFAR10 on Google Cloud with tensorflow_cloud and CloudTuner\n",
        "\n",
        "This example is based on [Keras-Tuner CIFAR10 sample](https://github.com/keras-team/keras-tuner/blob/master/examples/cifar10.py) to demonstrate how to run HP tuning jobs using\n",
        "[tensorflow_cloud](https://github.com/tensorflow/cloud) and Google Cloud Platform at scale.\n",
        "\n",
        "\u003ctable align=\"left\"\u003e\n",
        "    \u003ctd\u003e\n",
        "        \u003ca href=\"https://colab.research.google.com/github/tensorflow/cloud/blob/master/src/python/tensorflow_cloud/examples/hp_tuning_cifar10_using_google_cloud.ipynb\"\u003e\n",
        "            \u003cimg width=\"50\" src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"\u003eRun in Colab\n",
        "        \u003c/a\u003e\n",
        "    \u003c/td\u003e\n",
        "    \u003ctd\u003e\n",
        "        \u003ca href=\"https://github.com/tensorflow/cloud/blob/master/src/python/tensorflow_cloud/examples/hp_tuning_cifar10_using_google_cloud.ipynb\"\u003e\n",
        "            \u003cimg src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"\u003eView on GitHub\n",
        "        \u003c/a\u003e\n",
        "     \u003c/td\u003e\n",
        "    \u003ctd\u003e\n",
        "        \u003ca href=\"https://www.kaggle.com/nitric/hp-tuning-cifar10-using-google-cloud\"\u003e\n",
        "            \u003cimg width=\"90\" src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle logo\"\u003eRun in Kaggle\n",
        "        \u003c/a\u003e\n",
        "     \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a751fAMsyu0q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import uuid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_cloud as tfc\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzxvWrVJyu0q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if not tfc.remote():\n",
        "    print(tfc.__version__)\n",
        "    if tfc.__version__ \u003c '0.1.12':\n",
        "        raise RuntimeError(\"This example requires tensorflow_cloud version 0.1.12 or newer!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp5cSPtmyu0q"
      },
      "source": [
        "Set project parameters For Google Cloud Specific parameters refer to [Google Cloud Project Setup Instructions](https://www.kaggle.com/nitric/google-cloud-project-setup-instructions/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWTbtTKjyu0r",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set Google Cloud Specific parameters\n",
        "\n",
        "# TODO: Please set GCP_PROJECT_ID to your own Google Cloud project ID.\n",
        "GCP_PROJECT_ID = 'YOUR_PROJECT_ID'  #@param {type:\"string\"}\n",
        "\n",
        "# TODO: Change the Service Account Name to your own Service Account\n",
        "SERVICE_ACCOUNT_NAME = 'YOUR_SERVICE_ACCOUNT_NAME' #@param {type:\"string\"}\n",
        "SERVICE_ACCOUNT = f'{SERVICE_ACCOUNT_NAME}@{GCP_PROJECT_ID}.iam.gserviceaccount.com'\n",
        "\n",
        "# TODO: set GCS_BUCKET to your own Google Cloud Storage (GCS) bucket.\n",
        "GCS_BUCKET = 'YOUR_GCS_BUCKET_NAME' #@param {type:\"string\"}\n",
        "\n",
        "# DO NOT CHANGE: Currently only the 'us-central1' region is supported.\n",
        "REGION = 'us-central1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fcR9MWGyu0r",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Set Tuning Specific parameters\n",
        "\n",
        "# OPTIONAL: You can change the project name to any string.\n",
        "JOB_NAME = 'cifar10' #@param {type:\"string\"}\n",
        "\n",
        "# OPTIONAL:  Set Number of concurrent tuning jobs that you would like to run.\n",
        "NUM_JOBS = 5 #@param {type:\"string\"}\n",
        "\n",
        "# TODO: Set the study ID for this run. Study_ID can be any unique string.\n",
        "# Reusing the same Study_ID will cause the Tuner to continue tuning the\n",
        "# Same Study parameters. This can be used to continue on a terminated job,\n",
        "# or load stats from a previous study.\n",
        "# Note Study ID MUST NOT be auto generated for example using random or time,\n",
        "# as at run time each job will rerun this code and will create a separate study.\n",
        "STUDY_NUMBER = '00001' #@param {type:\"string\"}\n",
        "STUDY_ID = f'{GCP_PROJECT_ID}_{JOB_NAME}_{STUDY_NUMBER}'\n",
        "\n",
        "# Setting location were training logs and checkpoints will be stored\n",
        "GCS_BASE_PATH = f'gs://{GCS_BUCKET}/{JOB_NAME}/{STUDY_ID}'\n",
        "TENSORBOARD_LOGS_DIR = os.path.join(GCS_BASE_PATH,\"logs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXa6ZOFUyu0r"
      },
      "source": [
        "## Authenticating the notebook to use your Google Cloud Project\n",
        "\n",
        "For Kaggle Notebooks click on \"Add-ons\"-\u003e\"Google Cloud SDK\" before running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6CeeNUayu0s",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Using tfc.remote() to ensure this code only runs in notebook\n",
        "if not tfc.remote():\n",
        "\n",
        "    # Authentication for Kaggle Notebooks\n",
        "    if \"kaggle_secrets\" in sys.modules:\n",
        "        from kaggle_secrets import UserSecretsClient\n",
        "        UserSecretsClient().set_gcloud_credentials(project=GCP_PROJECT_ID)\n",
        "\n",
        "    # Authentication for Colab Notebooks\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        from google.colab import auth\n",
        "        auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H974JA6Kyu0s"
      },
      "source": [
        "## Load and prepare data\n",
        "Read raw data and split to train and test data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7yxJFuxyu0s",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "data = tfds.load('cifar10')\n",
        "train_ds, test_ds = data['train'], data['test']\n",
        "\n",
        "def standardize_record(record):\n",
        "    return tf.cast(record['image'], tf.float32) / 255., record['label']\n",
        "\n",
        "# Using a small batch size for local run\n",
        "# You can adjust the batch size for better performance in remote execution.\n",
        "train_ds = train_ds.map(standardize_record).cache().batch(64).shuffle(10000)\n",
        "test_ds = test_ds.map(standardize_record).cache().batch(64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93GborQLyu0s"
      },
      "source": [
        "## Define the model architecture and hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiCXZ8x8yu0t",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import kerastuner\n",
        "from tf.keras import layers\n",
        "\n",
        "# Configure the search space\n",
        "HPS = kerastuner.engine.hyperparameters.HyperParameters()\n",
        "\n",
        "HPS.Int('conv_blocks', 3, 5, default=3)\n",
        "for i in range(5):\n",
        "    HPS.Int('filters_' + str(i), 32, 256, step=32)\n",
        "    HPS.Choice('pooling_' + str(i), ['avg', 'max'])\n",
        "HPS.Int('hidden_size', 30, 100, step=10, default=50)\n",
        "HPS.Float('dropout', 0, 0.5, step=0.1, default=0.5)\n",
        "HPS.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
        "\n",
        "def build_model(hp):\n",
        "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
        "    x = inputs\n",
        "    for i in range(hp.get('conv_blocks')):\n",
        "        filters = hp.get('filters_'+ str(i))\n",
        "        for _ in range(2):\n",
        "            x = layers.Conv2D(\n",
        "              filters, kernel_size=(3, 3), padding='same')(x)\n",
        "            x = layers.BatchNormalization()(x)\n",
        "            x = layers.ReLU()(x)\n",
        "        if hp.get('pooling_' + str(i)) == 'max':\n",
        "            x = layers.MaxPool2D()(x)\n",
        "        else:\n",
        "            x = layers.AvgPool2D()(x)\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    x = layers.Dense(hp.get('hidden_size'),\n",
        "      activation='relu')(x)\n",
        "    x = layers.Dropout(hp.get('dropout'))(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(\n",
        "        hp.get('learning_rate')),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PiUpk5Qyu0t"
      },
      "source": [
        "## Configure a CloudTuner\n",
        "In this section we configure the cloud tuner for both remote and local execution. The main difference between the two is the distribution strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHZYCIVzyu0u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tensorflow_cloud import CloudTuner\n",
        "\n",
        "distribution_strategy = None\n",
        "if not tfc.remote():\n",
        "    # Using MirroredStrategy to use a single instance with 4 GPUs\n",
        "    # during remote execution while using no strategy for local.\n",
        "    distribution_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "tuner = CloudTuner(\n",
        "    build_model,\n",
        "    project_id=GCP_PROJECT_ID,\n",
        "    project_name= JOB_NAME,\n",
        "    region=REGION,\n",
        "    objective='accuracy',\n",
        "    hyperparameters=HPS,\n",
        "    max_trials=100,\n",
        "    directory=GCS_BASE_PATH,\n",
        "    study_id=STUDY_ID,\n",
        "    overwrite=False,\n",
        "    distribution_strategy=distribution_strategy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-Xy_8rLyu0u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Configure Tensorboard logs\n",
        "callbacks=[\n",
        "    tf.keras.callbacks.TensorBoard(log_dir=TENSORBOARD_LOGS_DIR)]\n",
        "\n",
        "# Setting to run tuning remotely, you can run tuner locally to validate it works first.\n",
        "if tfc.remote():\n",
        "    tuner.search(train_ds, epochs=30, validation_data=test_ds, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoSh_qpeyu0v"
      },
      "source": [
        "## Start the remote training\n",
        "\n",
        "This step will prepare your code from this notebook for remote execution and start NUM_JOBS parallel runs remotely to train the model. Once the jobs are submitted you can go to the next step to monitor the jobs progress via Tensorboard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkv23aGIyu0v",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if not tfc.remote():\n",
        "    print('Training on TensorFlow Cloud...')\n",
        "\n",
        "    # If you are using a custom image you can install modules via requirements txt file.\n",
        "    with open('requirements.txt','w') as f:\n",
        "        f.write('pandas==1.1.5\\n')\n",
        "        f.write('numpy==1.18.5\\n')\n",
        "        f.write('tensorflow-cloud==0.1.11\\n')\n",
        "        f.write('keras-tuner==1.0.2\\n')\n",
        "\n",
        "    # Optional: Some recommended base images. If you provide none the system will choose one for you.\n",
        "    TF_GPU_IMAGE= \"tensorflow/tensorflow:latest-gpu\"\n",
        "    TF_CPU_IMAGE= \"tensorflow/tensorflow:latest\"\n",
        "\n",
        "\n",
        "    tfc.run_cloudtuner(\n",
        "        distribution_strategy='auto',\n",
        "        requirements_txt='requirements.txt',\n",
        "        docker_config=tfc.DockerConfig(\n",
        "            parent_image=TF_GPU_IMAGE,\n",
        "            image_build_bucket=GCS_BUCKET\n",
        "            ),\n",
        "        chief_config=tfc.COMMON_MACHINE_CONFIGS['K80_4X'],\n",
        "        job_labels={'job': JOB_NAME},\n",
        "        service_account=SERVICE_ACCOUNT,\n",
        "        num_jobs=NUM_JOBS\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNKPyyuSyu0w"
      },
      "source": [
        "# Training Results\n",
        "While the training is in progress you can use Tensorboard to view the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHABiYmpyu0w",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if not tfc.remote():\n",
        "\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir TENSORBOARD_LOGS_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWn1BZ5Cyu0w"
      },
      "source": [
        "You can access the training assets as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fviMBs1Tyu0x",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if not tfc.remote():\n",
        "    tuner.results_summary(1)\n",
        "    best_model = tuner.get_best_models(1)[0]\n",
        "    best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
        "\n",
        "    # References to best trial assets\n",
        "    best_trial_id = tuner.oracle.get_best_trials(1)[0].trial_id\n",
        "    best_trial_dir = tuner.get_trial_dir(best_trial_id)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "hp-tuning-cifar10-using-google-cloud.ipynb",
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/tensorflow_cloud/src/python/tensorflow_cloud/examples/hp_tuning_cifar10_using_google_cloud.ipynb?workspaceId=chavoshi:Sample_notebooks::citc",
          "timestamp": 1612314954631
        },
        {
          "file_id": "/piper/depot/google3/third_party/tensorflow_cloud/src/python/tensorflow_cloud/examples/hp_tuning_cifar10_using_google_cloud.ipynb?workspaceId=chavoshi:Sample_notebooks::citc",
          "timestamp": 1612314842909
        },
        {
          "file_id": "/piper/depot/google3/third_party/tensorflow_cloud/src/python/tensorflow_cloud/examples/hp_tuning_cifar10_using_google_cloud.ipynb?workspaceId=chavoshi:Sample_notebooks::citc",
          "timestamp": 1612314447008
        },
        {
          "file_id": "/piper/depot/google3/third_party/tensorflow_cloud/src/python/tensorflow_cloud/examples/hp_tuning_cifar10_using_google_cloud.ipynb?workspaceId=chavoshi:Sample_notebooks::citc",
          "timestamp": 1612308359503
        },
        {
          "file_id": "/piper/depot/google3/third_party/tensorflow_cloud/src/python/tensorflow_cloud/examples/hp_tuning_cifar10_using_google_cloud.ipynb?workspaceId=chavoshi:Sample_notebooks::citc",
          "timestamp": 1612305956809
        },
        {
          "file_id": "/piper/depot/google3/third_party/tensorflow_cloud/src/python/tensorflow_cloud/examples/hp_tuning_cifar10_using_google_cloud.ipynb?workspaceId=chavoshi:Sample_notebooks::citc",
          "timestamp": 1612305835605
        },
        {
          "file_id": "1c9EUp0M1aCjSIognIAEKNw-BeXEXyGIG",
          "timestamp": 1612153028437
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
